"""
Service de scoring IA pour l'analyse des candidatures
Utilise Anthropic Claude pour analyser la compatibilit√© candidat-offre
"""
import os
import json
from typing import Dict, Optional
from anthropic import AsyncAnthropic
from dotenv import load_dotenv

load_dotenv()

class AIEvaluationService:
    def __init__(self):
        self.api_key = os.getenv("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY n'est pas d√©finie dans les variables d'environnement")
        
        self.client = AsyncAnthropic(api_key=self.api_key)
        self.model = "claude-3-5-sonnet-20241022"  # Dernier mod√®le Claude 3.5 Sonnet
    
    async def score_candidate(
        self,
        job_title: str,
        job_description: str,
        job_requirements: Optional[str],
        job_responsibilities: Optional[str],
        candidate_cv_text: str,
        candidate_experience: Optional[str] = None,
        candidate_skills: Optional[str] = None,
    ) -> Dict:
        """
        Analyse la compatibilit√© entre un candidat et une offre d'emploi
        
        Returns:
            Dict avec:
            - score: float (0-100)
            - strengths: List[str] - Points forts du candidat
            - weaknesses: List[str] - Points √† am√©liorer
            - skills_match: Dict - Comp√©tences match√©es
            - experience_match: str - √âvaluation de l'exp√©rience
            - recommendation: str - Recommandation globale
        """
        
        prompt = self._build_evaluation_prompt(
            job_title=job_title,
            job_description=job_description,
            job_requirements=job_requirements,
            job_responsibilities=job_responsibilities,
            candidate_cv_text=candidate_cv_text,
            candidate_experience=candidate_experience,
            candidate_skills=candidate_skills,
        )
        
        try:
            message = await self.client.messages.create(
                model=self.model,
                max_tokens=2000,
                temperature=0.3,  # Peu de cr√©ativit√©, plus de pr√©cision
                system="Tu es un expert en recrutement et √©valuation de candidatures. "
                       "Tu analyses objectivement la compatibilit√© entre un candidat et une offre d'emploi. "
                       "Tu fournis des √©valuations pr√©cises, structur√©es et factuelles bas√©es sur les donn√©es fournies.",
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )
            
            # Extraire le contenu de la r√©ponse
            response_text = message.content[0].text
            
            # Parser la r√©ponse JSON
            result = json.loads(response_text)
            
            return result
            
        except Exception as e:
            print(f"Erreur lors de l'analyse IA: {e}")
            # Retourner un score par d√©faut en cas d'erreur
            return {
                "score": 50.0,
                "strengths": ["Analyse IA indisponible"],
                "weaknesses": ["Analyse IA indisponible"],
                "skills_match": {"matched": [], "missing": [], "percentage": 0},
                "experience_match": "Non analys√©",
                "recommendation": "Analyse manuelle recommand√©e",
                "error": str(e)
            }
    
    def _build_evaluation_prompt(
        self,
        job_title: str,
        job_description: str,
        job_requirements: Optional[str],
        job_responsibilities: Optional[str],
        candidate_cv_text: str,
        candidate_experience: Optional[str],
        candidate_skills: Optional[str],
    ) -> str:
        """Construit le prompt pour Claude"""
        
        prompt = f"""Analyse la compatibilit√© entre ce candidat et cette offre d'emploi.

üìã OFFRE D'EMPLOI:
Titre: {job_title}

Description:
{job_description}
"""
        
        if job_requirements:
            prompt += f"\nExigences:\n{job_requirements}\n"
        
        if job_responsibilities:
            prompt += f"\nResponsabilit√©s:\n{job_responsibilities}\n"
        
        prompt += f"""

üë§ PROFIL CANDIDAT:

CV:
{candidate_cv_text[:3000]}  # Limiter √† 3000 caract√®res pour √©viter d√©passement token
"""
        
        if candidate_experience:
            prompt += f"\nExp√©riences:\n{candidate_experience}\n"
        
        if candidate_skills:
            prompt += f"\nComp√©tences:\n{candidate_skills}\n"
        
        prompt += """

üìä ANALYSE DEMAND√âE:
√âvalue la compatibilit√© du candidat avec l'offre sur une √©chelle de 0 √† 100.

Fournis ta r√©ponse UNIQUEMENT en format JSON valide (sans markdown, sans backticks) avec cette structure exacte:

{
  "score": 85.5,
  "strengths": [
    "Force 1 d√©tect√©e",
    "Force 2 d√©tect√©e",
    "Force 3 d√©tect√©e"
  ],
  "weaknesses": [
    "Point faible 1",
    "Point faible 2"
  ],
  "skills_match": {
    "matched": ["Comp√©tence 1", "Comp√©tence 2", "Comp√©tence 3"],
    "missing": ["Comp√©tence manquante 1", "Comp√©tence manquante 2"],
    "percentage": 75
  },
  "experience_match": "Description de l'ad√©quation de l'exp√©rience (2-3 phrases)",
  "recommendation": "Recommandation finale (shortlist / interview / review / reject) avec justification courte"
}

Crit√®res d'√©valuation:
- Comp√©tences techniques: 40%
- Exp√©rience pertinente: 30%
- Formation/dipl√¥mes: 15%
- Soft skills (si mentionn√©s): 10%
- Ad√©quation culturelle/sectorielle: 5%

R√©ponds UNIQUEMENT avec le JSON, rien d'autre.
"""
        
        return prompt


# Instance singleton du service
ai_service = AIEvaluationService()
